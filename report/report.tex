\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage[pdftex]{graphicx}
\usepackage[T1]{fontenc}
\usepackage[italian]{babel}
\usepackage{listings}

    
\title{\textbf{Report del progetto di Big Data: \\ analisi dei crimini nella città di Chicago}}

\author{
	Alessia Ventani - Mat. 901809\\
	Simone Venturi - Mat. }
	
\date{\today}

\begin{document}
\maketitle
\newpage

\tableofcontents

\newpage

\section{Teachers' notes}

The goal of the project is to assess the students' skills in writing jobs of low/medium complexity and to correctly reason about the jobs' performances. The projects must be agreed with the teachers (do not start without explicit consent) and it consists of:

\begin{itemize}
\item finding a complex-enough dataset: about 1GB, possibly consisting of more tables;
\item loading the dataset on HDFS/Hive;
\item implement an analytical job in both MapReduce and Spark;
\item writing a short report to describe it.
\end{itemize}

To deliver the project, each group must {\bf send by email to both teacher the link to their repository}. The repository must:
\begin{itemize}
\item be created from the individual assignment available on the Github classroom;
\item contain a {\sf report} folder with the PDF of the final report (based on this template). The report can be written in either Italian/English and Latex/Word at your discretion. Be concise and go straight to the point: an excessively verbose report is a waste of time for you and for the teachers;
\item contain a {\sf README.md} file with the instruction to run the jobs. Indeed, the teachers must be able to clone the repository and run the jobs from their accounts on the cluster. This means that the dataset must be accessible on HDFS/Hive and the code must compile and run correctly. Please make the jobs repeatable (i.e., the job checks and possibly deletes old data to avoid errors when re-running the code).
\end{itemize}

This guide is based on the ``MapReduce+Spark'' kind of project. However, we remind that a different kind of project may be agreed upon.
\\

The evaluation will be based on the following.
\begin{itemize}
\item Compliance of the jobs with the agreed upon specifications.
\item Compliance of the report with this guide.
\item Job correctness.
\item Correct reasoning about optimizations.
\end{itemize}

Appreciated aspects.
\begin{itemize}
\item Code cleanliness and comments.
\item Further considerations in terms of job scalability and extensibility.
\end{itemize}



\section{Introduzione}
\subsection{Descrizione del dataset}

Please provide:
\begin{itemize}
\item A brief description of the dataset.
\item The link to the website publishing the dataset (e.g., \url{https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page}).
\item Direct links to the downloaded files, especially if more than one files are available in the previous link (e.g., \url{https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2017-01.csv}).
\end{itemize}

Per questo elaborato si è deciso di utilizzare gli open data che la città di Chicago rende accessibili on-line. 
Fra i vari dataset presenti, ci si è concentrati su quello riportante i crimini commessi nella città Chicago dal 2001 ad oggi, aggiornati 
a sette giorni precedenti la data del download. I dati sono estratti dal CLEAR, acronimo di Citizen Law Enforcement Analysis and Reporting, 
del dipartimento di polizia della città. Per motivi ovvi di privacy, i nomi propri sono omessi e gli indirizzi non riconducono 
ad una specifica posizione geografica ma ad un'area, più o meno grande in base al grado di granularità del campo, della città. \\
I dati utilizzati sono scaricabili ai seguenti link:
\begin{itemize}
\item elenco dei crimini registrati: \url{https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2}
\item elenco dei codici univoci di report dei crimini dello stato dell'Illinois: \url{https://data.cityofchicago.org/Public-Safety/Chicago-Police-Department-Illinois-Uniform-Crime-R/c7ck-438e} 
\end{itemize}
Dai link riportati è possibile scaricare i dati premendo sul tasto Export e scegliendo il formato "CSV Excel for Europe".
 
\subsubsection{Descrizione dei file}

For each file, briefly indicated the available data and the fields used for the analyses; examples are welcome.


L'analisi si basa sull'utilizzo di un unico file csv di partenza formato con i dati dei crimini registrati a Chicago.
Nella tabella sono presenti 22 colonne che riportano informazioni di varie categorie: le informazioni riguardanti il tipo di codice, la sua collocazione temporale e spaziale (comprese le coordinate), se è stato effettuato un arresto o meno e se il crimine è domestico. Di queste colonne sono stati considerati solo alcuni campi.\\
 Per il primo job sono stati utilizzati:
\begin{itemize}
\item IUCR: codice univoco di identificazione di un crimine per lo stato dell'Illinois;
\item Description: breve descrizione del crimine riportato;
\item District: codice corrispondente al distretto di polizia in cui è avvenuto il crimine.
\end{itemize}
Per la seconda elaborazione ci si è concentrati su:
\begin{itemize}
\item IUCR: codice univoco di identificazione di un crimine per lo stato dell'Illinois;
\item Description: breve descrizione del crimine riportato;
\item Arrest: booleano che indica se per il crimine è stato effettuato un arresto o meno;
\item Year: anno in cui è avvenuto il crimine.
\end{itemize}

Un esempio di dati riportati è:\\
IUCR Description District Arrest Year \\
0460   SIMPLE      006    False  2020



\section{Preparazione dei dati}
Please provide:
\begin{itemize}
\item The paths to each file on HDFS and/or its corresponding location in Hive (database and table); consider relying on the structured data lake organization.
\item A subsection with details on the pre-processing of the data (only necessary if the data is dirty and/or it contains a significant amount of useless information).
\end{itemize}

I dati considerati non hanno avuto bisogno di operazioni di pre-elaborazione complesse data la loro natura. Si noti però che all'interno del dataset, essendo compilato manualmente, potrebbero esserci degli errori accidentali nei dati ma questo non costituisce un grosso problema per le elaborazioni che si intendono eseguire. \\

Per poter effettuare dei confronti nel primo job, vedi descrizione nella sezione successiva, sono state preparate due versioni del file inziale.
La prima costituisce il file scaricato dal sito nella sua versione integrale mentre per la seconda si è deciso di dividere la tabella iniziale in due:
\begin{itemize}
\item la prima comprende tutti i campi ad eccezione di "Primary Type" e "Description". Per ottenere questo file è stato fatto eseguire il seguente codice spark:
\begin{lstlisting}

spark.read.format("csv")
  .option("sep", ";").option("header", "true")
  .option("mode", "DROPMALFORMED")
  .load(<path to input file>)
  .drop("Primary Type","Description").coalesce(1)
  .write.format("com.databricks.spark.csv")
  .option("sep", ";").option("header", "true")
  .save(<path to output file>)

\end{lstlisting}

\item la seconda riporta i campi "IUCR","Primary Type" e "Description". In questo caso non è stato necessario elaborare il file di partenza ,a è stato semplicemente scaricato l'elenco dei codici univoci di report dei crimini dello stato dell'Illinois. In quest'ultimo però alcuni codice IUCR non presentavano lo zero iniziare e quindi per farli coincidere con quelli presenti nella prima si è dovuto aggiungere questa cifra, operazione effettuata manualmente dato il basso numero di record con questa caratteristica. 
\end{itemize}

Come formato si è deciso di caricare il file csv e utilizzare come separatore il simbolo ; per facilitare le operazioni nel paradigma map reduce.

I file sono stati caricati in hdfs e sono raggiungibili a:
%TODO



\section{Jobs}

One subsection for each job.

\subsection{Job \#1: short description}

Provide a brief, general description of the job. Then, one subsubsection for each implementation.

\subsubsection{MapReduce/Spark implementation}

Please provide:
\begin{itemize}
\item Input and output files/tables.
\item Execution time and amount of resources.
\item Direct links to the application's history on YARN (e.g., \url{http://isi-vclust0.csr.unibo.it:18088/history/application_15...}).
\item Description of the implementation. A schematic and concise discussion is preferrable to a verbose narrative. Focus on how the data is manipulated in the job (e.g., what do keys and values represent across the different stages, what operations are carried out). 
\item Performance considerations with respect the (potentially) carried out optimizations, e.g., in terms of:
\begin{itemize}
\item allocated resources and tasks;
\item enforced partitioning;
\item data caching;
\item combiner usage;
\item broadcast variables usage;
\item any other kind of optimization.
\end{itemize}
\item Short extract of the output and discussion (i.e., whether there is any relevant insight obtained).
\end{itemize}

\section{Miscellaneous}

If necessary, feel free to add sections to explain any other relevant information.

\end{document}
